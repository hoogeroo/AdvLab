{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double click and enter your name here:** Fistname Lastname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double click and enter your university ID number here:** 123456789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A practical guide to experimental uncertainties\n",
    "\n",
    "Real experiments and <span class='myclass'>real</span> measurements are not perfect. Because of parasitic phenomena, sensitivity of the experiment to noise, or mis-reading of scales, the result we get are generally not the exact value we would like it to be. Moreover, when repeating the same measurement, we often obtain a different result! These \"errors\" in measurements, more properly called **uncertainties**, need to be properly estimated and quoted when you write up your results. Failure to do so may mean that your results are useless. \n",
    "\n",
    "This tutorial/assignment explains you **first** how to estimate uncertainties in individual and repeated measurements  (part A) and **second** how to \"propagate\" these in a calculation (part B).\n",
    "\n",
    "It mixes material to read with practial exercises to run with Python. **These exercises are directly relevant to what you will have to do in the lab.** You will probably find yourself re-use some of the code below to calculate your results. So the more serious you do this assignment, the easier your life will be in the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Estimating uncertainties in measurements\n",
    "\n",
    "Here you are, facing the measuring apparatus of your experiment. This could be a simple ruling stick, a dial with a moving pointer, or the digital display of some sensor. You are reading a value off that measuring tool. What is the uncertainty on that value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1 Uncertainty in an individual measurement\n",
    "\n",
    "The uncertainty in a <i>non-repeated</i> measurement can be estimated as **the minimum resolution of the measuring device**. This is often quoted as being half of the smallest division of the measuring apparatus. For example, a reasonable estimate of uncertainty in a single measurement with a typical meter stick, which has ticks every one millimeter, is &plusmn;&nbsp;0.5&nbsp;mm. Similary, with a digital voltmeter that diplays three significant digits, like 3.73&nbsp;V, the uncertainty would correspond to half the value associated with the least significant digit, in this case &plusmn;&nbsp;0.005&nbsp;V.\n",
    "\n",
    "**It may happen that the value you are trying to read is slowly, randomly varying over time,** because of parastic phenomena (e.g. vibrations). Say for example that your voltage reading varies betwen 3.68 and&nbsp;3.76&nbsp;V. In that case, you would quote the measurement as the mean value between the minimum and maximum value you can read, (3.68 V + 3.76 V) / 2 = 3.72 V, and the uncertainty as half the spread of values, (3.76 V &minus;&nbsp;3.68 V) / 2 = 0.04 V, giving you for this example a reading of 3.72&nbsp;&plusmn;&nbsp;0.04&nbsp;V. More on this below.\n",
    "\n",
    "As a general rule, if you estimate the uncertainty of a quantity in two different ways, and you get two different results (e.g. &plusmn;&nbsp;0.005&nbsp;V from the resolution, and &plusmn;&nbsp;0.04&nbsp;V from the fluctuations), you use the **largest** value for the uncertainty. Essentially, you neglect the one that has the least influence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider again the above example, but this time imagine the oscillations are slow enough that you can read ten different values of that measurement. You put these in a Python/NumPy array (you will learn more about that if you do the \\#213 experiment on Python):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "import numpy as np\n",
    "values = np.array([3.68, 3.78, 3.77, 3.71, 3.66, 3.70, 3.71, 3.73, 3.71, 3.74])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the uncertainty in each of the *individual* measurements above? Clearly, it is **NOT** half the smallest digit, &plusmn;&nbsp;0.005&nbsp;V, as it is obviously varying more than that. Here, **the standard deviation of your data** can serve as the uncertainty of individual measurements. The rationale is that, for process fluctuating based on a Gaussian statistics, 68% of repeated measurements occur in a range of the mean value &plusmn;&nbsp;1&nbsp;standard deviation. Therefore, the uncertainty in one additional measurement is **approximately** (see next Section for some extra detais) one standard deviation of the previous measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<span style='color: red;'>Calculate the standard deviation of the values above using Numpy's `np.std(...)` function.</span> Type your code for this operation in the empty cell below. Make sure to execute it by typing `Shift + Enter` within the code cell, or by clicking the play button in the toolbar above. **NOTE:** You first need to execute the cell above (with `Shift + Enter`) to load Numpy and define the `values` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's answer to the above calculation will probably have many decimals places. Given that the data you started with, in the `values` vector above, have only two decimal places, it does not make any sense to include more than two decimal places in the uncertainty &mdash; because you do not even know the data that well. In fact, there is never a good reason to quote an uncertainty with more than one or two significant figures. <span style='color: red;'>Take this into account to quote below the uncertainty you have obtained.</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2 Uncertainty in a mean\n",
    "\n",
    "Now consider that, in the hope of getting a \"better\" result, you take the *mean* of the ten measurements contained in the `values` vector defined above. What is the uncertainty of that mean?\n",
    "\n",
    "Owing to the mean being centered between lower and higher values, that uncertainty is expected to be **less** than the uncertainty of an individual measurement. This suggests that the standard deviation is **NOT** an estimate of\n",
    "the uncertainty in a mean.\n",
    "\n",
    "The uncertainty in a mean is also expected to decrease with additional measurements (as the mean converges to its 'true' value). The fact that the standard deviation may increase or decrease with additional measurements suggests again that the standard deviation is **NOT** an estimate of the uncertainty in a mean.\n",
    "\n",
    "The correct way of estimating the uncertainty in a mean is to **divide the standard deviation of the values by the square root of the number *N* of values**. This results in an uncertainty that is less than the standard deviation and decreases with increasing *N*, both requirements for an uncertainty in a mean. This is called the **standard error of the mean** or simply **standard error**, often labelled as $\\sigma_\\mathrm{m}$. If $\\sigma$ denotes the standard deviation of the data, we thus have\n",
    "\n",
    "$$\\sigma_\\mathrm{m} = \\frac{\\sigma}{\\sqrt{N}}\\,.$$\n",
    "\n",
    "An additional problem occurs when the amount of data collected (the \"sample\", of size $N$) is small. In that case, the standard deviation of the **sample**, $s$, is not quite the standard deviation of the underlying probabilitic **population**, $\\sigma$. To estimate the latter, one needs **to scale the sample standard deviation $s$, as**\n",
    "\n",
    "$$\\sigma \\approx \\sqrt{\\frac{N}{N-1}} s$$\n",
    "\n",
    "Note how $\\sigma$ approaches the sample standard deviation $s$ for a large number of samples, $N$. The above expression is actually the one you want to use to calculate uncertainties in individual measurements. With that, the standard error becomes\n",
    "\n",
    "$$\\sigma_\\mathrm{m} = \\frac{s}{\\sqrt{N-1}}$$\n",
    "\n",
    "**So, to quote the result of an experiment in which your measure the same quantity *N* times, you would quote the mean of your samples as the nominal value, and the standard error as its uncertainty.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "<span style='color:red;'>Calculate the mean of the `values` vector (using Numpy's `np.mean(...)` function). Assign it to a variable and print it.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_mean = ...\n",
    "print(values_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red;'>From the `values_mean` variable calculated above, calculate the standard error.</span> Use `values.size` to get the number of elements *N* of the `values` vector, and the `sqrt(...)` function (from the **math** module) to calculate square roots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red;'>Quote the mean of the values and its uncertainty in the box below (where it says \"*Type your answer here*\").</span> Use the &plusmn;&nbsp;symbol to quote the uncertainty, like 3.1&nbsp;&plusmn;&nbsp;0.5. In the cell below, which is a 'text' cell (or Markdown cell), this can be typed as\n",
    "\n",
    "    3.1 &plusmn; 0.5 (HTML syntax) or  \n",
    "    3.1 $\\pm$ 0.5 (LaTeX syntax)\n",
    "    \n",
    "    \n",
    "and will be rendered as 3.1 &plusmn; 0.5 when 'running' the cell (`Shift+Enter`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Type your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.3 The case of random processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometime, the value you are measuring is varying because it comes from an intrinsically random process. You may encounter this case e.g. with experiment&nbsp;\\#251, *Radioactivity*, where the number of radioactive decays counted in a set time interval varies from measurements to measurements. *This variation is caused by the physics of radioactive decay, not by any imprecision in your measurement*. Here estimating the uncertaintly (which really is the standard deviation that you would observe over many such measurements) should be guided by your knowledge of the random process. For radioactive decay counts, which follows a Poisson distribution, a count of *N* is affected by an uncertaintly of $\\sqrt{N}$.\n",
    "\n",
    "**So, in this case, the nominal value would be the mean of *N* measurements, and the uncertainty would be the square-root of that mean. Do not use the standard error for this case.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.4 Relative uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you quote uncertainties in the form 3.1&nbsp;&plusmn;&nbsp;0.2, we say that&nbsp;0.2 is the <b>absolute</b> uncertainty. \n",
    "\n",
    "You can also use <b>relative uncertainties</b>, i.e. quote uncertainties using percentages. In this way, you quote the uncertainty as a percentage of the nominal value. For the example above, 0.2 / 3.1 x 100% = 6.5%, so we could quote it as 3.1&nbsp;&plusmn;&nbsp;6.5%. \n",
    "\n",
    "<b>Relative uncertainties help you put things into perspective.</b> If we are measuring a distance, you may think that 100&nbsp;m is a \"big\" uncertainty. But without knowing the magnitude of the actual distance, that statement (\"big\" uncertainty) does not carry any sense. \n",
    "\n",
    "If we were measuring the distance between a home and the dairy three houses down the road, about 50&nbsp;m away, then a 100&nbsp;m uncertainty is \"big\". The only thing clear about a distance of 50&nbsp;m&nbsp;&plusmn;&nbsp;100&nbsp;m is that, really, we do not know that distance without any meaningful precision. And indeed the relative uncertainty on that measurement is 100/50 x 100% = 200%.\n",
    "\n",
    "Contrast that with the measurement of the distance between the top of two of Auckland's volcanic cones, say 6.5&nbsp;km away. Now the distance is 6500&nbsp;m&nbsp;&plusmn;&nbsp;100&nbsp;m =&nbsp;6500&nbsp;m&nbsp;&plusmn;&nbsp;1.5%. Now that uncertainty of 100&nbsp;m is not so big after all. The measurement is precise within&nbsp;1.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<span style=\"color: red;\">Calculate the **relative** uncertainty of 175&nbsp;&plusmn;&nbsp;12.</span> Express you result in %.  \n",
    "**NOTE**: you can use Python as a normal calculator. Just type, e.g. `(1+5)*2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">Quote the above result using a \"meaningful\" number of significant digits.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Type your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<span style=\"color: red;\">Calculate the **absolute** uncertainty of 1285&nbsp;&plusmn;&nbsp;3.5%.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">Again, quote the above result using a \"meaningful\" number of significant digits.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Type your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Consider a radio-active decay process (see Section A.3 above). <span style='color:red;'>How many events should you wait for your detector to count to have a 5% accuracy on your count? Calculate that in the cell below.</span>\n",
    "\n",
    "**Note:** In Python, the power operator is `**`, like 4\\**2&nbsp;= &nbsp;4<sup>2</sup>. Also, the square root is accessed with the `sqrt(...)` function. If you need that latter function, you need to import the `math` module first, which has been done above, when defining the `values` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Propagation of uncertainties\n",
    "\n",
    "Ok. We now have measured some data AND have estimated the uncertainties in these data. In a typical experiment, we would now use these data to calculate some results. The question is, given the uncertainties in the data, what is the uncertainty on the result. This procedure is called *propagation of uncertainties* and is an important part of the job. \n",
    "\n",
    "Imagine you are traveling a distance of 20&nbsp;m in 4&nbsp;s. Your velocity is 20&nbsp;m&nbsp;/&nbsp;4&nbsp;s =&nbsp;5&nbsp;m/s. Now if that distance is known &plusmn;&nbsp;2&nbsp;m, and the time &plusmn;&nbsp;1&nbsp;s, what is the uncertainty on the velocity? It is easy to think through this by considering what could be the minimal velocity (smallest distance over largest possible time, (20&minus;2)&nbsp;m&nbsp;/&nbsp;(4+1)&nbsp;s =&nbsp;3.6&nbsp;m/s) as well as maximal velocity (largest distance over smallest possible time, (20+2)&nbsp;m&nbsp;/&nbsp;(4&minus;1)&nbsp;s =&nbsp;7.3&nbsp;m/s). Then you take the mean and (half) the spread between these two values to arrive at a result of 5.45 &plusmn; 1.85 m/s.\n",
    "\n",
    "Clearly, you can see that this will quickly become very tedious, especially for complex mathematical formula, and there must be a better way. Below we will see the (simplified) rules that govern the *arithmetics of uncertainties*, and how to deal with that efficiently using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1 How to represent uncertainties in Python\n",
    "\n",
    "Python provides the **uncertainties** module to make calculations with uncertainties easy. The basic module is loaded with the statement below. Note that here we also load the standard **math** module to have access to other math functions, in particular the square-root function, `sqrt`. <span style='color:red;'>Execute the cell below to get you started.</span>\n",
    "\n",
    "**NOTE:** That module is available by default on the Advanced Lab computer, but you may not have that module installed by default in your Python installation. Download it (find it on https://pypi.python.org/pypi/uncertainties) and install it if you need. If you are using Microsoft Azure, execute the line below (this may take a few seconds to complete). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install uncertainties   # Run this line to install the module if you are using Microsoft Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainties import *\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having loaded the uncertainties module, a new type called <b>ufloat</b> is available. It allows to associate an error (standard deviation) to any normal float number. <span style='color:red;'>Execute the three cell below to see what they do.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ufloat(4, 0.1)      # this means  4 +/- 0.1\n",
    "y = ufloat(10, 0.3)     # this means 10 +/- 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)     # printing x should now display the uncertainty, as 4.0+/-0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y            # no need for print(...) if all one wants is to print the value of a single variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic calculations and syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can then perfom calculations with uncertainties using normal Python operators. <span style='color:red;'>Execute the two cells below to see it in action.</span> In principle, that is (almost) all there is to know, but keep reading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x + y\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the nominal value and uncertainty using the dot notation as below. This will come handy later. Suppose x = 4.0 &plusmn; 0.1. Then\n",
    "\n",
    "> `x.nominal_value` (or `x.n` as shortcut) returns 4.0  \n",
    "> `x.std_dev` (or `x.s` as shortcut) returns 0.1  \n",
    "> `x.s/x.n*100` returns the relative uncertainty in %, here 2.5%\n",
    "\n",
    "***\n",
    "\n",
    "<span style='color:red;'>Try these below.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2 Basic rules for addition/substraction/multiplication/division\n",
    "\n",
    "Rather than blindly taking what Python outputs, let us try to understand how uncertainties are propagated in a calculation. For these labs, we will assume that all our uncertainties have a *Gaussian statistical distribution*. For x = 4 &plusmn; 0.1, that means that the probability distribution that leads to these (seemingly) random values for *x* as we keep measuring it have a Gaussian distribution, centered on 4 (the mean) and with a 0.1 standard deviation. Gaussian distributions have that property that there is a 68% chance that the actual (exact) value is within &plusmn;&nbsp;1 standard deviation of the nominal value (here, 4). Distributions are not always Gaussians but there are many reasons why they often turn out to be Gaussian. In particular, this is often the case for *repeated measurements* where you have estimated the uncertainties with the standard deviation and standard error (see part A).\n",
    "\n",
    "When **adding or sbustracting** two values with Gaussian uncertainties, $z = x + y$ or $z = x - y$, the laws of probabilites predict that the uncertainty $\\sigma_z$ on the result $z$ is given by\n",
    "$$\\sigma_z = \\sqrt{\\sigma_x^2 + \\sigma_y^2}$$\n",
    "where $\\sigma_x$ ($\\sigma_y$) is the uncertainty of $x$ ($y$). If you have more than two variables to add, just keep adding the uncertainties-squared inside the square-root in the above formula. This way of \"adding\" the (absolute) uncertainties by \"taking the square-root of the sum of the squares\" is said to be a **quadrature sum of uncertainties**. The fact that the uncertainty $\\sigma_z$ is not just the direct sum of the uncertainties (which would be larger) reflects the fact that, given that the uncertainties are random (and have random signs), they will not always act in the same direction. And when you take into account all the possibilities, with their probabilities, you get the quadrature-sum result. Notice also how uncertainties always **add**, even when **substracting** the values.\n",
    "\n",
    "When **multiplying or dividing**  two values with Gaussian uncertainties, $z = x * y$ or $z = x / y$, the **relative**  uncertainty $\\sigma_z/z$ on the result is the quadrature sum of the **relative** uncertainties,\n",
    "$$\\frac{\\sigma_z}{z} = \\sqrt{\\left(\\frac{\\sigma_x}{x}\\right)^2 + \\left(\\frac{\\sigma_y}{y}\\right)^2}$$\n",
    "So, same rule as for addition and substraction, except using the **relative** uncertainties instead of the **absolute** ones. Again, this can be generalized to any number of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<span style='color:red;'>Verify the propagation formula for addition above by applying it to add x = 4 &plusmn; 0.1 to y = 3 &plusmn; 0.2. In the cell below, assign these two values to variables, print the sum (`print(x+y)`), which will also show the uncertainty on the result as calculated by Python, and then calculate **explicity** the same uncertainty using the quadrature-sum rule (don't just type the numbers directly in your calculation; rather access the uncertainty  on `x` with `x.s` and so on &mdash; see above). Print that result and compare to check you get the same uncertainty with the two methods. If not, check you code.</span>\n",
    "\n",
    "**NOTE:** you can have multiple statements, including mutliple print statements, in the same cell, by writing them on top of each other in separate lines. Everything is evaluated at once, and all the results shown below, when you press `Shift+Enter`. Also note that assigning to a variable does not produce any output (like `u = 4 + 5`). You need to add a `print(u)` statement to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ...        # 4 +/- 0.1\n",
    "y = ...        # 3 +/- 0.2\n",
    "print(x+y)\n",
    "print(...)     # explicit calculation. Use sqrt(...), x.s, and the ** operator for powers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<span style='color: red;'>Repeat the exercise for substraction, (75 &plusmn; 3) &minus; (71 &plusmn; 4), both directly (the Python way; assign the result to a variable called `z` &mdash; it will come handy below) and explicitely.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ...        # 75 +/- 3\n",
    "y = ...        # 71 +/- 4\n",
    "z = ...\n",
    "print(z)\n",
    "print(...)     # explicit calculation of uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: red;'>Calculate and print the *relative* uncertainties on $x$ and $y$, as well as for their difference $x-y$. Compare them and comment/explain your observations in the next cell.</span> Also, take note: substracting two values close from each other, and whose uncertainty intervals overlap (or nearly overlap), gives a very poor estimate of the result. If the uncertainty on that result is not  satisfactory, you have no choice but to go back to your measurements and attempt to get lower uncertainies on $x$ and&nbsp;$y$ (for example by averaging over a larger set of repeated measurements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x: {:.2f}%'.format(x.s/x.n*100))   # this neatly prints the relative uncertainty of x with 2 decimal places\n",
    "print(...)     # do the same for y\n",
    "print(...)     # do the same for the difference. Use the varialbe z defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment on the result here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<span style='color: red;'>Consider the *multiplication* z = x*y. Calculate the uncertainty with Python, and then explicitely with the multiplication rule. Check the results are the same.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<span style='color:red;'>Now consider the following problem. Two forces $F_1 = 45 \\pm 3$&nbsp;N and $F_2 = 18 \\pm 4$&nbsp;N act on the same object, in the same direction, and moves it by a distance $d = 3 \\pm 0.1$&nbsp;m in a time $t = 8.0 \\pm 1.5$&nbsp;s. Calculate the **power** used to realize this displacement, $$P = \\frac{(F_1 + F_2) \\cdot d}{t}\\,,$$including its uncertainty, directly using Python, and also explicitely using the quadrature sum rules above. Take as many lines and define as many intermediate variables as necessary &mdash; see if you can get the two uncertainties to match.</span> By this time, you should start to like the Python way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = ...      # 45 +/- 3 N\n",
    "F2 = ...\n",
    "d = ...\n",
    "t = ...\n",
    "P = ...\n",
    "print(P)\n",
    "...           # explicit calculation of uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.3 A few more rules and the concept of independent/dependent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<span style='color:red;'>Set x = 5 &plusmn; 0.4 and calculate z = 2x with Python. Print the result neatly &mdash; code provided below.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ...\n",
    "z = ...\n",
    "\n",
    "print(\"     x = {:5f}\".format(x))      # the '5f' means format the number as a Float, right justified over 5 spaces\n",
    "print(\"z = 2x = {:5f}\".format(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red;'>Now cleverly consider that 2x = x + x and apply (explicitely) the rule for the uncertainty of the sum. What uncertainty do you get for the result this way?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Notice  how your two results are **different**. What is going on? And what is the right way? Also notice that the uncertainty calculated by Python simply appears to be 2 times the uncertainty on `x`. \n",
    "\n",
    "The trick here is that **the quadrature-sum rules for the propagation of uncertainties** laid out above (for the sum/difference/product/division) **are only correct if the uncertainties in the different variables are independent**. What does that mean? When we say *x* = 5 &plusmn; 0.4, all we know is that there is a 68% chance that the TRUE value of  and *x* lies in the interval [5 &minus; 0.4 ; 5 + 0.4]. In particular, we do not know if it is larger or smaller than&nbsp;5. If I consider a second variable, *y* = 3 &plusmn; 0.2, again I do not know whether the true value of *y* is larger or smaller than&nbsp;3. Now if *x* and *y* are *independent*, the fact that the true value of *x* is &mdash; say &mdash; larger than&nbsp;5 does not imply anything as to the true value of *y*. It could still be larger or smaller than&nbsp;3 with equal probabilities. There are no **correlations** between the errors on the two variables &mdash; in particular their relative sign is random. In contrast, **dependant** variables would exhibit such correlations. For example, we may know, because of specificities of the experiment, that if I measure a value for *x* that is too large, then my measurement for the value of *y* will also be too large. Such uncertainties are said to **correlated**, hence **not independent**. If the uncertainties of two variables systematically have the opposite sign, they are said to be **anti-correlated**.\n",
    "\n",
    "Clearly, when I calculate *x* + *x* the two terms in this addition are actually the same, and therefore are **not indepedent**. The quadrature sum rule therefore does not apply, and the 2nd result calculated above is NOT correct. Python gives the right result. In fact, the Python's **uncertainties** module is quite clever. Even if you have many intermediate results, that depend somehow on the same variable(s), it will correctly track the dependant and independant variables for you. This makes your life much (much) easier!\n",
    "\n",
    "Ok, what is the right rule to calculate the uncertainty of *z* = 2 *x*? Well consider that we can write *z* = 2 *x* as z = x \\* y, with y = 2. Note that the variable *y*, which is the (exact) number&nbsp;2, has no correlation with *x* whatsoever. These are independent variables and we can apply the product rule for uncertainties as defined above. But what is the uncertainty on *y*? Well clearly, it is zero, $\\sigma_y = 0$: since *y* is an **exact** number, it has no uncertainties.\n",
    "\n",
    "***\n",
    "\n",
    "<span style='color:red;'>With that in mind, calculate **explicity** the uncertainty on z = 2*x with the <b>product</b> rule and see how it compares with Python's result above (you should get the same uncertainty as Python).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "From your calculation, the following new rule should be clear: **When multiplying/dividing a variable $x$ by an exact scalar $a$ (or vice versa), $z = a x$, or $z = x/a$, or $z = a/x$,  the relative uncertainty on $z$ is the same as the relative uncertainty on $x$:**\n",
    "\n",
    "$$\\frac{\\sigma_z}{z} =  \\frac{\\sigma_x}{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "\n",
    "<span style='color:red;'>Set *x* = 25 &plusmn; 2. Calculate z = 1/*x* (with Python). Then calculate and print the **relative** uncertainties on *x* and *z*. Check that they are the same.</span> **NOTE:** you can copy the percentage-print statement used in Section B.2 above to have a neat output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ...\n",
    "z = ...\n",
    "print(...)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "We have one more important basic rule to look at. This one applies to powers. If I try to calculate the uncertainty in $z = x^2$ by writing it as $z = x * x$, and by applying the product rule, clearly I will have a problem: the two factors in my product are again **not independent** (they are the same). The rule for this case is the following:\n",
    "\n",
    "**For $z = x^a$, where $a$ is an exact scalar, the relative uncertainty in $z$ is $a$ times the relative uncertainty of $x$,**\n",
    "\n",
    "$$\\frac{\\sigma_z}{z} = a \\frac{\\sigma_x}{x}$$\n",
    "In fact, if you think about it carefully, this is like applying the product rule (quadrature sum of relative uncertainties) but instead of doing a **quadrature sum**, you do a **normal sum** instead. The rationale is that, if the variables are dependent, like in $x * x$, we consider the worst case scenario with all uncertainties acting **in the same direction**, rather than in random directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<span style='color:red;'>Exercise: consider a uniformly accelerated motion, $x = a t^2/2$, when the acceleration $a = 5 \\pm 0.2\\ \\mathrm{m/s^2}$ and the time $t = 8.3 \\pm 0.7\\ \\mathrm{s}$. Calculate the uncertainty on $x$, direclty using Python, and also explicity using all the rules as appropriate.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ...\n",
    "t = ...\n",
    "x = ...\n",
    "print(x)\n",
    "...                  # explicit calculation of the uncertainty in x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.4 Propagation of uncertainties in functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes a result is obtained through calculations involving more complex functions than addition and multiplication. To handle this case, one has to load the <b>umath</b> sub-module of the uncertainties module. <span style='color:red;'>Execute the next cell.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainties.umath import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a value $x_1 = 2 \\pm 0.1$, and, as an example of a (complicated) function, let us calculate the logarithm of that value with Python. This is done by the code below. <span style='color:red;'>Make sure you understand the code, and execute that cell.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = ufloat(2, 0.1)\n",
    "y1 = log(x1)\n",
    "print(\"x1 = {:f}\".format(x1))\n",
    "print('x1: {:.2f}%'.format(x1.s/x1.n*100))        # displaying the relative uncertainty\n",
    "print(\"log(x1) = {:f}\".format(y1))\n",
    "print('log(x1): {:.2f}%'.format(y1.s/y1.n*100))   # displaying the relative uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how Python still provides you with the uncertainty on the result. To try to understand the rule behind it, let us try a different value of $x$ but with **same (absolute) uncertainty**. <span style='color:red;'>Execute the code below.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = ufloat(15, 0.1)\n",
    "y2 = log(x2)\n",
    "print(\"x2 = {:f}\".format(x2))\n",
    "print('x2: {:.2f}%'.format(x2.s/x2.n*100))        # displaying the relative uncertainty\n",
    "print(\"log(x2) = {:f}\".format(y2))\n",
    "print('log(x2): {:.2f}%'.format(y2.s/y2.n*100))   # displaying the relative uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the two results does not really make clear what is going on. In the first case, the relative uncertainy of $\\log(x_1)$ was larger than that of $x_1$, in the second case it is the other way around. There is no clear pattern in the absolute uncertainties either.\n",
    "\n",
    "To clarify this point, let us make a plot of the log function. In the plot below, we also highlight (in green) the ranges covered by $x_1 \\pm \\sigma_{x_1}$ (from $x_1 - \\sigma_{x_1}$ to $x_1 + \\sigma_{x_1}$) and $x_2 \\pm \\sigma_{x_2}$. Similarly, we highlight the ranges covered by $y_1$ and $y_2$ (in red), i.e. the logs of $x_1$ and $x_2$, with their  uncertainties as calculated by Python above. This is done using the **matplotlib** module. <span style='color:red;'>You do not need to understand all the details. Just execute the code below and the graph should appear.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "xx = np.arange(0.5,20,0.01)\n",
    "yy = np.log(xx)\n",
    "\n",
    "fig = plt.figure(num=1, figsize=(8,6))\n",
    "plt.fill_between(xx, yy, -1.0, where=(np.abs(xx-x1.n)<x1.s), color='g')\n",
    "plt.fill_between(xx, yy, -1.0, where=(np.abs(xx-x2.n)<x2.s), color='g')\n",
    "plt.fill_betweenx(yy, xx, where=(np.abs(yy-y1.n)<y1.s), color='r')\n",
    "plt.fill_betweenx(yy, xx, where=(np.abs(yy-y2.n)<y2.s), color='r')\n",
    "plt.title(\"y = log(x)\"); plt.xlabel(\"x\"); plt.ylabel(\"y\")\n",
    "plt.plot(xx, yy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe first how the two green bars have the same thickness. This is because we have chosen the same **absolute** uncertainties for $x_1$ and $x_2$. However, you can also see how the green bar on the left, centered on $x_1=2$, **intercepts a wider vertical swath of the (blue) log curve** than around $x_2=15$ on the right. This naturally explains why the **absolute** uncertainty on $y_1$ is larger than that for $y_2$, as visualized by the different thicknesses of the **red** bars.\n",
    "\n",
    "Pushing this to the limit: If the blue curve was purely horizontal (constant function, say $y=2$), the uncertainty on $x$ would have absolutely no influence on the uncertainty on $y$. After all, $y=2$ is an **exact** number, with no uncertainty.\n",
    "\n",
    "The above discussion should make clear that **what drives the propagation of uncertainties in a function is the slope of that function. A steep slope (larger than&nbsp;1) amplifies absolute uncertainties. A weak slope (lower than &nbsp;1) dampen it.**\n",
    "\n",
    "This leads to the following equation to calculate propagation of uncertainty through a function. If $y = f(x)$, then\n",
    "\n",
    "$$ \\sigma_y = \\frac{df}{dx} \\sigma_x $$\n",
    "\n",
    "***\n",
    "\n",
    "<span style='color:red;'>Keeping in mind that the derivative of the $\\log(x)$ function is equal to $1/x$, use the above formula to calculate **explicitely** the uncertainty on $y_1 = log(x_1)$. Check that it matches Python's result above.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a function of several variables, $u = f(x,y,z)$, the result above can be generalized. Not unsurpisingly, one has to do a <b>quadrature sum</b> (assuming uncertainties on $x$, $y$, and $z$ are independent) of the contribution of each variable to the uncertainty. This leads to\n",
    "\n",
    "$$ \\sigma_u = \\sqrt{\\left(\\frac{\\partial f}{\\partial x} \\sigma_x\\right)^2 + \\left(\\frac{\\partial f}{\\partial y} \\sigma_y\\right)^2 + \\left(\\frac{\\partial f}{\\partial z} \\sigma_z\\right)^2}$$\n",
    "\n",
    "All the specific uncertainty propagation formula described in the previous Sections can be derived from this more general result. For example, for the sum rule:\n",
    "\n",
    "If $u = f(x,y) = x+y$, one has $\\partial f/\\partial x = 1$ and $\\partial f/\\partial y = 1$. This leads to $\\sigma_u = \\sqrt{\\sigma_x^2+\\sigma_y^2}$ as expected.\n",
    "\n",
    "<span style='color:red;'>Optional: try to derive (on a piece of paper) the rule for products and powers.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.5 A few more useful tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even when you write custom-functions, the general multi-variable propagation formula is applied automatically for you by the **uncertainties** module. This is demonstrated below through the definition of a simple function that returns $u = x + 2y$. <span style='color:red;'>Execute the code below to see it in action.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(x,y):\n",
    "    u = x + 2*y\n",
    "    return u\n",
    "\n",
    "x = ufloat(4, 0.2, tag='x')    # 4 +/- 0.2\n",
    "y = ufloat(5, 0.1, tag='y')    # 5 +/- 0.1 \n",
    "u = myfunc(x,y)\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we have <b>tagged</b> the variables, ie we have given them names. For complicated functions, this makes it easier to track how each variables contribute to the uncertainty in the final result. This information is accessed as below (notice how we apply the error_components() method on the result $u$). <span style='color:red;'>Execute the code below.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.error_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see that $x$ and $y$ both contributes by the same amount (0.2) to the uncertainty on $u$. That is because $y$ is multiplied by 2 in the function, therefore its uncertainty is doubled. The uncertainty on $u$ is the quadrature sum of these contributions as confirmed below. <span style='color:red;'>Execute the code below and compare with the uncertainty on *u* obtained above.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(sum([error**2 for var,error in u.error_components().items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For functions that are designed to only handle floats (e.g. because they are defined in an external C library), you can make them compatible with the **uncertainties** module by calling the wrap function on them. \n",
    "\n",
    "    wrap_f = wrap(myfunc)     # myfunc is the name of a function that does not work with uncertainties\n",
    "    \n",
    "You can then call `wrap_f` with arguments with uncertainties, and it will return uncertainties like\n",
    "\n",
    "    wrap_f(x,y)\n",
    "    \n",
    "The **uncertainties** module also works on Numpy arrays of numbers, facilitating parallel calculations over many values. Check the documentation (available on the web) for these cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.6 A few more exercises\n",
    "\n",
    "Now use your knowledge of Python and of the **uncertainties** module to solve the problems below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The following are the results of 10 measurements of a length (in mm):\n",
    "\n",
    "    [32.84, 32.55, 33.10, 33.04, 32.63, 33.02, 32.73, 33.21, 32.95, 32.70]\n",
    "\n",
    "<span style='color:red;'>(a) Calculate the best estimate of the length (i.e. the mean)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red;'>(b) Calculate the precision of each *individual* measurement?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red;'>(c) How well is the length determined as a result of all ten measurements? I.e. calculate the uncertainty in the mean?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red;'>(d) Quote the result in form xx &plusmn; yy, with an appropriate number of significant figures.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Type your result here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red;'>Suppose that $z = x + y$ is the sum of two independent measurements, with $x \\simeq50$. Suppose also that $y$ is\n",
    "approximately one-hundredth of the value of $x$. If the **relative** uncertainty of $x$ is 5%, calculate and print\n",
    "the **relative** uncertainty in $z$, assuming that the **relative** uncertainty in $y$ is\n",
    "\n",
    "<span style='color:red;'>(a) &plusmn; 1%,  \n",
    "(b) <span style='color:red;'>&plusmn; 10%,  \n",
    "(c) <span style='color:red;'>&plusmn; 30%.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red;'>What conclusion can you draw about estimating the uncertaintty in the sum of two quantities when one quantity is much larger than the other?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Type your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<span style='color:red;'>Calculate the volume of a cylinder, and its uncertainty, given that it has a height $h$ of 24.7&nbsp;cm&nbsp;&plusmn;&nbsp;0.8&nbsp;cm and a radius $R$ of 8.2&nbsp;mm&nbsp;&plusmn;&nbsp;0.1&nbsp;mm. Remember that the volume of a cylinder is given by $V = \\pi R^2 h$.</span> **NOTE:** In Python, you can access the value of $\\pi$ with `pi` (assuming the **math** module is loaded) or as `np.pi` if **Numpy** has been imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The refractive index of a material determines the ratio of the angle of incidence $\\theta_\\mathrm{i}$ to the\n",
    "angle of refraction $\\theta_\\mathrm{r}$ of light as, starting from air, it crosses the material boundary [Snell's Law $ùëõ = \\sin\\theta_\\mathrm{i}/\\sin\\theta_\\mathrm{r}$]. <span style='color:red;'>If measurements of $\\theta_\\mathrm{i}$ and $\\theta_\\mathrm{r}$ have means of $\\pi/6$ and $\\pi/8$ respectively and the standard error of each is $\\pi/200$, what are the best values of $n$ and its uncertainty?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
